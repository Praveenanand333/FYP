{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2352 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Praveen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  eeg_data = eeg_data.replace(encode)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data = aq10_data.replace({'YES':1, 'NO':0, '?':'Others', 'others':'Others'})\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:63: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data = aq10_data.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:65: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  aq10_data['gender'].replace('m',0,inplace=True)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  aq10_data['gender'].replace('f',1,inplace=True)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:66: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data['gender'].replace('f',1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Praveen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  eeg_data = eeg_data.replace(encode)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data = aq10_data.replace({'YES':1, 'NO':0, '?':'Others', 'others':'Others'})\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:63: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data = aq10_data.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:65: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  aq10_data['gender'].replace('m',0,inplace=True)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  aq10_data['gender'].replace('f',1,inplace=True)\n",
      "C:\\Users\\Praveen\\AppData\\Local\\Temp\\ipykernel_9356\\1541906609.py:66: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq10_data['gender'].replace('f',1,inplace=True)\n",
      "c:\\Users\\Praveen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 437ms/step - accuracy: 0.5158 - loss: 22048810205184.0000 - val_accuracy: 0.4975 - val_loss: 15177742286848.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 417ms/step - accuracy: 0.5175 - loss: 14608279535616.0000 - val_accuracy: 0.5007 - val_loss: 23376221437952.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 418ms/step - accuracy: 0.5234 - loss: 10987811897344.0000 - val_accuracy: 0.5098 - val_loss: 11506198511616.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 417ms/step - accuracy: 0.5174 - loss: 18747655979008.0000 - val_accuracy: 0.5074 - val_loss: 4988482879488.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.4991 - loss: 14456650203136.0000 - val_accuracy: 0.5147 - val_loss: 9162962501632.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 411ms/step - accuracy: 0.5027 - loss: 10940653240320.0000 - val_accuracy: 0.4951 - val_loss: 3044748296192.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.4882 - loss: 49002733109248.0000 - val_accuracy: 0.4937 - val_loss: 15324614230016.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 411ms/step - accuracy: 0.4925 - loss: 11296977190912.0000 - val_accuracy: 0.5039 - val_loss: 7002710343680.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.5115 - loss: 3134493294592.0000 - val_accuracy: 0.4898 - val_loss: 4706841657344.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.4996 - loss: 3450643152896.0000 - val_accuracy: 0.4930 - val_loss: 1550333771776.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 413ms/step - accuracy: 0.5243 - loss: 4975843344384.0000 - val_accuracy: 0.4965 - val_loss: 6992608886784.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 416ms/step - accuracy: 0.4802 - loss: 8030864801792.0000 - val_accuracy: 0.5011 - val_loss: 13756218212352.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 418ms/step - accuracy: 0.5141 - loss: 9155119153152.0000 - val_accuracy: 0.5028 - val_loss: 14101155676160.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 424ms/step - accuracy: 0.4999 - loss: 6524225716224.0000 - val_accuracy: 0.5112 - val_loss: 1620716421120.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 424ms/step - accuracy: 0.5090 - loss: 18194720882688.0000 - val_accuracy: 0.5137 - val_loss: 1796220256256.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 424ms/step - accuracy: 0.5179 - loss: 2833267294208.0000 - val_accuracy: 0.5060 - val_loss: 3303531347968.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 426ms/step - accuracy: 0.5109 - loss: 8751341895680.0000 - val_accuracy: 0.4989 - val_loss: 712918827008.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m82/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.4921 - loss: 2830577958912.0000"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SMOTE Balancing Function\n",
    "def apply_smote(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Function to downsample the larger datasets\n",
    "def downsample(X, y, target_size):\n",
    "    X_downsampled, y_downsampled = resample(X, y, replace=True, n_samples=target_size, random_state=42)\n",
    "    return X_downsampled, y_downsampled\n",
    "\n",
    "# 1. Load and Preprocess Image Data from train/test/val directories\n",
    "# 1. Load and Preprocess Image Data from train/test/val directories\n",
    "def load_image_data(image_dir):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    image_data = datagen.flow_from_directory(image_dir, target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)\n",
    "    \n",
    "    # Use pretrained ResNet50 for feature extraction\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Extract features from images\n",
    "    features = base_model.predict(image_data)\n",
    "    \n",
    "    image_features = features.reshape(features.shape[0], -1)  # Flatten features\n",
    "    labels = image_data.classes  # Get labels from directory structure\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    image_features, labels = apply_smote(image_features, labels)\n",
    "    \n",
    "    return image_features, labels\n",
    "\n",
    "\n",
    "# 2. Load and Preprocess EEG Data from CSV\n",
    "def load_eeg_data(csv_file):\n",
    "    eeg_data = pd.read_csv(csv_file)\n",
    "    encode = ({'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 0} )\n",
    "    eeg_data = eeg_data.replace(encode)\n",
    "    scaler = StandardScaler()\n",
    "    eeg_data_scaled = scaler.fit_transform(eeg_data.drop('label', axis=1))  # Assuming 'label' column contains the labels\n",
    "    \n",
    "    labels = eeg_data['label'].values  # Extract labels\n",
    "    \n",
    "    eeg_data_balanced, labels = apply_smote(eeg_data, labels)  # Apply SMOTE\n",
    "    \n",
    "    return eeg_data_balanced, labels\n",
    "\n",
    "# 3. Load and Preprocess AQ10 Data from CSV\n",
    "def load_aq10_data(csv_file):\n",
    "    aq10_data = pd.read_csv(csv_file)\n",
    "    aq10_data = aq10_data.replace({'YES':1, 'NO':0, '?':'Others', 'others':'Others'})\n",
    "    aq10_data = aq10_data.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
    "    aq10_data = aq10_data.drop(columns=['autism'])\n",
    "    aq10_data['gender'].replace('m',0,inplace=True)\n",
    "    aq10_data['gender'].replace('f',1,inplace=True)\n",
    "    aq10_data = pd.get_dummies(aq10_data, columns=['ethnicity'])\n",
    "    aq10_data = aq10_data.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
    "    aq10_data = pd.get_dummies(aq10_data, columns=['relation'])\n",
    "    aq10_data = aq10_data.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
    "    aq10_data.drop(\"age_desc\",axis=1,inplace=True)\n",
    "    for i in aq10_data['age']:\n",
    "        q1 =aq10_data['age'].quantile(0.25)\n",
    "        q3 = aq10_data['age'].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_tail = q3 + 1.5 * iqr\n",
    "        lower_tail = q1 - 1.5 * iqr\n",
    "        if i > upper_tail or i < lower_tail:\n",
    "            if i> upper_tail:\n",
    "               aq10_data['age'] = aq10_data['age'].replace(i, upper_tail)\n",
    "            else:\n",
    "                aq10_data['age'] = aq10_data['age'].replace(i, np.mean(i))\n",
    "    aq10_data['age'] = aq10_data['age'].fillna(0) \n",
    "    aq10_data=aq10_data.drop(columns=['country_of_res'])\n",
    "    aq10_data=aq10_data.drop(columns=['used_app_before'])\n",
    "    aq10_data=aq10_data.drop(columns=['result'])\n",
    "    scaler = StandardScaler()\n",
    "    aq10_data_scaled = scaler.fit_transform(aq10_data.drop('Class/ASD', axis=1))  # Assuming 'label' column contains the labels\n",
    "    \n",
    "    labels = aq10_data['Class/ASD'].values  # Extract labels\n",
    "    \n",
    "    aq10_data_balanced, labels = apply_smote(aq10_data_scaled, labels)  # Apply SMOTE\n",
    "    \n",
    "    return aq10_data_balanced, labels\n",
    "\n",
    "# 4. Equalize the Dataset Sizes\n",
    "def equalize_datasets(*datasets):\n",
    "    # Get the minimum dataset size\n",
    "    min_size = max([len(data[0]) for data in datasets])\n",
    "    \n",
    "    # Downsample each dataset to the minimum size\n",
    "    downsampled_datasets = [downsample(data[0], data[1], min_size) for data in datasets]\n",
    "    \n",
    "    return downsampled_datasets\n",
    "\n",
    "# 5. Combine Features\n",
    "def combine_features(image_features, eeg_features, aq10_features):\n",
    "    combined_features = np.concatenate([image_features, eeg_features, aq10_features], axis=1)\n",
    "    return combined_features\n",
    "\n",
    "# 6. Neural Network Training\n",
    "def train_combined_model(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification (0 or 1)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 7. Full Pipeline with Equalized Datasets\n",
    "def autism_prediction_pipeline(image_dir, eeg_csv_file, aq10_csv_file):\n",
    "    # Split labels into train/test sets based on your image folder split\n",
    "    image_features_train, y_train_img = load_image_data(f'{image_dir}/train')\n",
    "    eeg_features_train, y_train_eeg = load_eeg_data(eeg_csv_file)\n",
    "    aq10_features_train, y_train_aq10 = load_aq10_data(aq10_csv_file)\n",
    "    \n",
    "    # Ensure all datasets are of equal size\n",
    "    datasets_train = equalize_datasets((image_features_train, y_train_img),\n",
    "                                       (eeg_features_train, y_train_eeg),\n",
    "                                       (aq10_features_train, y_train_aq10))\n",
    "    \n",
    "    # Combine features for training\n",
    "    combined_train_features = combine_features(datasets_train[0][0], datasets_train[1][0], datasets_train[2][0])\n",
    "    combined_train_labels = datasets_train[0][1]\n",
    "    \n",
    "    # Load test datasets\n",
    "    image_features_test, y_test_img = load_image_data(f'{image_dir}/test')\n",
    "    eeg_features_test, y_test_eeg = load_eeg_data(eeg_csv_file)\n",
    "    aq10_features_test, y_test_aq10 = load_aq10_data(aq10_csv_file)\n",
    "    \n",
    "    datasets_test = equalize_datasets((image_features_test, y_test_img),\n",
    "                                      (eeg_features_test, y_test_eeg),\n",
    "                                      (aq10_features_test, y_test_aq10))\n",
    "    \n",
    "    combined_test_features = combine_features(datasets_test[0][0], datasets_test[1][0], datasets_test[2][0])\n",
    "    combined_test_labels = datasets_test[0][1]\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_combined_model(combined_train_features, combined_train_labels, combined_test_features, combined_test_labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(combined_test_features)\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    \n",
    "    print(classification_report(combined_test_labels, y_pred_binary))\n",
    "\n",
    "# Example Usage\n",
    "autism_prediction_pipeline('../Notebooks/Image/output', '../Notebooks/EEG/preprocessed_dataset.csv', '../Notebooks/Behavioural/autism_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
